{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3Cl7yKI1WKS"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "dataset = load_dataset('IlyaGusev/gazeta')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpKlZZSF5CLC",
        "outputId": "5470852c-fd92-45d2-dc70-0a5c89434f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'Сегодня транспортный налог начисляется в зависимости от мощности автомобиля, причем цена для «сильных» машин выше, чем для малолитражек. Также ставку налога могут корректировать региональные власти: согласно Налоговому кодексу, базовый тариф, установленный правительством, может быть уменьшен в пять раз или увеличен до 10 раз. Сборы идут в региональные бюджеты, откуда растекаются на общие нужды. Транспортный налог — один из основных источников бюджетных доходов — предлагается направить исключительно на дорожные фонды. Так, автомобилисты будут понимать, за что они платят, а дорожники будут иметь гарантированный доход. Кроме налога дорожные фонды будут пополняться за счет бюджетных средств и проезда по платным дорогам. Более того, транспортный налог предлагается завуалировать в акцизы на бензин. Привычную и раздражающую систему ежегодной оплаты квитанции предлагается изменить, включив налог в стоимость топлива. Минэкономразвития говорит об удвоении акцизы, которая сегодня составляет 3,32 рубля за литр 92-го и 95-го бензина. Теперь платить будет не тот, кто купил машину мощнее, а тот, кто больше ездит. Владельцам многосильных автомобилей, которые сегодня отдают в год по 45–50 тысяч за машину, нововведение явно выгодно. Также выигрывают хозяева нескольких автомобилей, которые используются поочередно. Если в семье две-три машины, которые много стоят в гараже и не эксплуатируются, сейчас приходится платить за все. По новой схеме сбор будет значительно меньше. Но владельцы экономичных машин будут выкладывать гораздо больше при равном пробеге. Если цена бензина вырастет на 3,32 рубля, то владелец вазовской «девятки», потребляющей на 100 км в городе около 10 литров, заплатит в год 10162 рубля при среднем пробеге 30 тыс. км вместо 550 руб. по квитанции, а за Citroen C3 мощностью 73 л. с. и расходом 8,5 л на «сотню» придется в год выложить около 8,5 тысяч рублей. Сейчас – 511 руб. Хорошо укомплектованный Ford Focus cо 145-сильным мотором за 30 тыс. км. обойдется в 11155 «налоговых» рублей – на 6800 рублей дороже, чем при существующей ставке налогообложения, а вот налог на пожилой Mercedes-Benz S420 в кузове W140 при новой системе снизится почти вдвое. Сейчас владелец платит в год за 279 л. с. мотора около 41850 рублей. При среднем пробеге в 30 тыс. км в год и расходе топлива порядка 20 л на 100 км он истратит всего 6000 литров бензина и заплатит в казну вдвое меньше – 19920 рублей. С точки зрения власти решение отмены транспортного налога понятное и верное. В первую очередь, собираемость налога тут же возрастет до 100%, потому что новая система исключает возможность уклониться от уплаты. Кроме того, налоговая инспекция сэкономит бюджетные средства на доставке квитанций и судебных издержках при выколачивании средств с неплательщиков. Автоматически решается вопрос с бюрократической неразберихой после продажи машины или утилизации, когда налоговые органы присылают квитанцию на давно проданную машину. Но главное, что при новой схеме сборы значительно возрастут. Власти рассчитывают собирать до 62 млрд рублей в год. Экономисты уже предвидят тотальное повышение цен из-за роста стоимости перевозок. Ведь за бензин придется переплачивать и логистическим компаниям, которые включат дополнительные расходы в цену товара. Получается, что теперь за дороги будут платить не только автомобилисты, но и те, кто за рулем никогда не сидел. Но даже с учетом всех оговорок отмена транспортного налога — это важный и сильный политический шаг, который поможет снять напряжение в регионах. Дело в том, что скрытое налогообложение делает поборы незаметными и не травмирующими. Ведь власти и сейчас любят педалировать тем, что в стране самый низкий в Европе подоходный налог 13%. При этом они не афишируют другие отчисления в бюджет, которые снимаются с граждан с теми же акцизами и НДС. Есть также сомнения, что власти смогут обеспечить прозрачность расходования средств. Дорожные фонды в России уже существовали и были расформированы в 2000 году за коррупционность. Как предполагается распределять деньги между регионами и федеральным дорожным агентством и кто будет следить за потоками, в правительстве пока не решили.',\n",
              " 'summary': 'С 2011 года правительство отменяет самый раздражающий граждан налог – транспортный. Но поборы автомобилистов не прекратятся – налоги завуалируют в бензиновые акцизы и платные дороги, а цены на товары подскочат. Зато теперь собираемые деньги обещают пустить только на строительство и содержание дорог.',\n",
              " 'title': 'Налог в бак',\n",
              " 'date': '2010-06-01 10:35:49',\n",
              " 'url': 'https://www.gazeta.ru/auto/2010/05/31_a_3377717.shtml'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "lr=3e-4\n",
        "max_input_length = 768\n",
        "max_target_length = 60\n",
        "batch_size = 4\n",
        "epochs = 5\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained('cointegrated/rut5-base')\n",
        "model = T5ForConditionalGeneration.from_pretrained('cointegrated/rut5-base').to(device)\n",
        "\n",
        "\n",
        "def preprocessing(examples):\n",
        "    inputs = ['summarize: ' + doc for doc in examples['text']]\n",
        "\n",
        "    model_inputs = tokenizer(\n",
        "        inputs,\n",
        "        max_length=max_input_length,\n",
        "        truncation=True,\n",
        "        padding=False,\n",
        "    )\n",
        "\n",
        "    labels = tokenizer(\n",
        "        examples[\"summary\"],\n",
        "        max_length=max_target_length,\n",
        "        truncation=True,\n",
        "        padding=False,\n",
        "    )\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "\n",
        "tokenized_dataset = dataset.map(\n",
        "    preprocessing,\n",
        "    batched=True\n",
        ")"
      ],
      "metadata": {
        "id": "QWrlwM_J5zJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFwGoCO8CI8j",
        "outputId": "adaadccb-c0f7-49e0-b64e-bc7ca870df80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.18)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.10.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (1.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (26.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.21.0)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (23.0.0)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.5.4)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (0.23.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2026.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: typer>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface-hub>=0.7.0->evaluate) (0.23.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.23.0->typer-slim->huggingface-hub>=0.7.0->evaluate) (8.3.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.23.0->typer-slim->huggingface-hub>=0.7.0->evaluate) (14.3.2)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.23.0->typer-slim->huggingface-hub>=0.7.0->evaluate) (0.0.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer>=0.23.0->typer-slim->huggingface-hub>=0.7.0->evaluate) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer>=0.23.0->typer-slim->huggingface-hub>=0.7.0->evaluate) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.23.0->typer-slim->huggingface-hub>=0.7.0->evaluate) (0.1.2)\n",
            "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds, tokenizer):\n",
        "    rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "    preds, labels = eval_preds\n",
        "\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
        "    decoded_labels = [label.strip() for label in decoded_labels]\n",
        "\n",
        "    result = rouge.compute(\n",
        "        predictions=decoded_preds,\n",
        "        references=decoded_labels,\n",
        "        use_stemmer=True,\n",
        "        rouge_types=[\"rouge1\", \"rouge2\", \"rougeL\"]\n",
        "    )\n",
        "\n",
        "    prediction_lens = [len(pred.split()) for pred in decoded_preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "\n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ],
      "metadata": {
        "id": "EDTqC7RlCFRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    num_train_epochs=epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size * 2,\n",
        "    learning_rate=lr,\n",
        "    weight_decay=0.01,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "    fp16=torch.cuda.is_available(),\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    compute_metrics=lambda p: compute_metrics(p, tokenizer),\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "print(\"TRAINED\")"
      ],
      "metadata": {
        "id": "4V9rX0x3K2Dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"Собирает батч и делает динамический паддинг\"\"\"\n",
        "    input_ids = [item[\"input_ids\"] for item in batch]\n",
        "    attention_mask = [item[\"attention_mask\"] for item in batch]\n",
        "    labels = [item[\"labels\"] for item in batch]\n",
        "\n",
        "    # Паддинг входов\n",
        "    input_ids = torch.nn.utils.rnn.pad_sequence(\n",
        "        [torch.tensor(ids) for ids in input_ids],\n",
        "        batch_first=True,\n",
        "        padding_value=tokenizer.pad_token_id\n",
        "    )\n",
        "\n",
        "    attention_mask = torch.nn.utils.rnn.pad_sequence(\n",
        "        [torch.tensor(mask) for mask in attention_mask],\n",
        "        batch_first=True,\n",
        "        padding_value=0\n",
        "    )\n",
        "\n",
        "    # Паддинг лейблов (с -100 для игнорирования паддинга в loss)\n",
        "    labels = torch.nn.utils.rnn.pad_sequence(\n",
        "        [torch.tensor(lab) for lab in labels],\n",
        "        batch_first=True,\n",
        "        padding_value=-100\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_mask\": attention_mask,\n",
        "        \"labels\": labels\n",
        "    }\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    tokenized_dataset[\"train\"],\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=2,\n",
        "    pin_memory=True if device.type == \"cuda\" else False,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    tokenized_dataset[\"validation\"],\n",
        "    batch_size=batch_size * 2,  # На валидации можно больший батч\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=2,\n",
        "    pin_memory=True if device.type == \"cuda\" else False,\n",
        ")\n",
        "\n",
        "\n",
        "def train_epoch(model, train_loader, criterion, opt, epoch, device):\n",
        "    epoch_loss = []\n",
        "\n",
        "    model.train()\n",
        "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch}')\n",
        "\n",
        "    for batch_idx, batch in enumerate(progress_bar):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=batch[\"input_ids\"],\n",
        "            attention_mask=batch[\"attention_mask\"],\n",
        "            labels=batch[\"labels\"]\n",
        "        )\n",
        "\n",
        "        loss = outputs.loss\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        epoch_loss.append(loss.item())\n",
        "\n",
        "    print(f'EPOCH {i + 1}')\n",
        "    print(f'TRAINING LOSS {np.mean(epoch_loss)}')\n",
        "    return np.mean(epoch_loss)\n",
        "\n",
        "\n",
        "def evaluate(model, val_loader, criterion, device):\n",
        "    epoch_loss = []\n",
        "\n",
        "    model.eval()\n",
        "    progress_bar = tqdm(val_loader, desc='Validation')\n",
        "    with torch.no_grad():\n",
        "        for batch in progress_bar:\n",
        "            outputs = model(\n",
        "                input_ids=batch[\"input_ids\"],\n",
        "                attention_mask=batch[\"attention_mask\"],\n",
        "                labels=batch[\"labels\"]\n",
        "            )\n",
        "\n",
        "            epoch_loss.append(outputs.loss.item())\n",
        "    print('VAL LOSS', np.mean(epoch_loss))\n",
        "    return np.mean(epoch_loss)\n",
        "\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "for i in range(epochs):\n",
        "    start_time = time.time()\n",
        "    train_epoch(model, train_loader, criterion, opt, i, device)\n",
        "    evaluate(model)\n",
        "    end_time = time.time()"
      ],
      "metadata": {
        "id": "4MZVQ3oZfdER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, tokenizer, text: str, num_beams: int = 4):\n",
        "    input_text = \"summarize: \" + text\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        input_text,\n",
        "        max_length=max_input_length,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_length=max_target_length,\n",
        "        )\n",
        "\n",
        "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "    print(f'TEST FOR NUMBER {i + 1}')\n",
        "    print(dataset['test'][i]['text'])\n",
        "    print(test_model(dataset['test'][i]['text']))\n",
        "    print()\n",
        "    print('PROJECTED SUMMARY:')\n",
        "    print(dataset['test'][i]['summary'])\n",
        "\n"
      ],
      "metadata": {
        "id": "jnzSNA2VF1xR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}